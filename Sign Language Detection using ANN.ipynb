{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3223e93d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\jodir\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jodir\\anaconda3\\lib\\site-packages (0.19.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\jodir\\anaconda3\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from torch) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from torch) (1.11.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from torch) (2023.4.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from torchvision) (1.24.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from jinja2->torch) (2.1.1)\n",
      "Requirement already satisfied: mpmath>=0.19 in c:\\users\\jodir\\anaconda3\\lib\\site-packages (from sympy->torch) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "089a5397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95fd84d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f57956f3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>107</td>\n",
       "      <td>118</td>\n",
       "      <td>127</td>\n",
       "      <td>134</td>\n",
       "      <td>139</td>\n",
       "      <td>143</td>\n",
       "      <td>146</td>\n",
       "      <td>150</td>\n",
       "      <td>153</td>\n",
       "      <td>...</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>155</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>156</td>\n",
       "      <td>157</td>\n",
       "      <td>156</td>\n",
       "      <td>158</td>\n",
       "      <td>158</td>\n",
       "      <td>...</td>\n",
       "      <td>69</td>\n",
       "      <td>149</td>\n",
       "      <td>128</td>\n",
       "      <td>87</td>\n",
       "      <td>94</td>\n",
       "      <td>163</td>\n",
       "      <td>175</td>\n",
       "      <td>103</td>\n",
       "      <td>135</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>187</td>\n",
       "      <td>186</td>\n",
       "      <td>187</td>\n",
       "      <td>188</td>\n",
       "      <td>187</td>\n",
       "      <td>...</td>\n",
       "      <td>202</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>199</td>\n",
       "      <td>198</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "      <td>195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>211</td>\n",
       "      <td>211</td>\n",
       "      <td>212</td>\n",
       "      <td>212</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>235</td>\n",
       "      <td>234</td>\n",
       "      <td>233</td>\n",
       "      <td>231</td>\n",
       "      <td>230</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>222</td>\n",
       "      <td>229</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13</td>\n",
       "      <td>164</td>\n",
       "      <td>167</td>\n",
       "      <td>170</td>\n",
       "      <td>172</td>\n",
       "      <td>176</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>...</td>\n",
       "      <td>92</td>\n",
       "      <td>105</td>\n",
       "      <td>105</td>\n",
       "      <td>108</td>\n",
       "      <td>133</td>\n",
       "      <td>163</td>\n",
       "      <td>157</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27450</th>\n",
       "      <td>13</td>\n",
       "      <td>189</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>193</td>\n",
       "      <td>...</td>\n",
       "      <td>132</td>\n",
       "      <td>165</td>\n",
       "      <td>99</td>\n",
       "      <td>77</td>\n",
       "      <td>52</td>\n",
       "      <td>200</td>\n",
       "      <td>234</td>\n",
       "      <td>200</td>\n",
       "      <td>222</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27451</th>\n",
       "      <td>23</td>\n",
       "      <td>151</td>\n",
       "      <td>154</td>\n",
       "      <td>157</td>\n",
       "      <td>158</td>\n",
       "      <td>160</td>\n",
       "      <td>161</td>\n",
       "      <td>163</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>...</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>196</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27452</th>\n",
       "      <td>18</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>121</td>\n",
       "      <td>196</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "      <td>206</td>\n",
       "      <td>204</td>\n",
       "      <td>203</td>\n",
       "      <td>202</td>\n",
       "      <td>200</td>\n",
       "      <td>200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27453</th>\n",
       "      <td>17</td>\n",
       "      <td>177</td>\n",
       "      <td>181</td>\n",
       "      <td>184</td>\n",
       "      <td>185</td>\n",
       "      <td>187</td>\n",
       "      <td>189</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>119</td>\n",
       "      <td>56</td>\n",
       "      <td>27</td>\n",
       "      <td>58</td>\n",
       "      <td>102</td>\n",
       "      <td>79</td>\n",
       "      <td>47</td>\n",
       "      <td>64</td>\n",
       "      <td>87</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27454</th>\n",
       "      <td>23</td>\n",
       "      <td>179</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>182</td>\n",
       "      <td>181</td>\n",
       "      <td>182</td>\n",
       "      <td>183</td>\n",
       "      <td>182</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>132</td>\n",
       "      <td>170</td>\n",
       "      <td>194</td>\n",
       "      <td>214</td>\n",
       "      <td>203</td>\n",
       "      <td>197</td>\n",
       "      <td>205</td>\n",
       "      <td>209</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27455 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0          3     107     118     127     134     139     143     146     150   \n",
       "1          6     155     157     156     156     156     157     156     158   \n",
       "2          2     187     188     188     187     187     186     187     188   \n",
       "3          2     211     211     212     212     211     210     211     210   \n",
       "4         13     164     167     170     172     176     179     180     184   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "27450     13     189     189     190     190     192     193     193     193   \n",
       "27451     23     151     154     157     158     160     161     163     164   \n",
       "27452     18     174     174     174     174     174     175     175     174   \n",
       "27453     17     177     181     184     185     187     189     190     191   \n",
       "27454     23     179     180     180     180     182     181     182     183   \n",
       "\n",
       "       pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  \\\n",
       "0         153  ...       207       207       207       207       206   \n",
       "1         158  ...        69       149       128        87        94   \n",
       "2         187  ...       202       201       200       199       198   \n",
       "3         210  ...       235       234       233       231       230   \n",
       "4         185  ...        92       105       105       108       133   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "27450     193  ...       132       165        99        77        52   \n",
       "27451     166  ...       198       198       198       198       198   \n",
       "27452     173  ...       121       196       209       208       206   \n",
       "27453     191  ...       119        56        27        58       102   \n",
       "27454     182  ...       108       132       170       194       214   \n",
       "\n",
       "       pixel780  pixel781  pixel782  pixel783  pixel784  \n",
       "0           206       206       204       203       202  \n",
       "1           163       175       103       135       149  \n",
       "2           199       198       195       194       195  \n",
       "3           226       225       222       229       163  \n",
       "4           163       157       163       164       179  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "27450       200       234       200       222       225  \n",
       "27451       196       195       195       195       194  \n",
       "27452       204       203       202       200       200  \n",
       "27453        79        47        64        87        93  \n",
       "27454       203       197       205       209       215  \n",
       "\n",
       "[27455 rows x 785 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train=pd.read_csv(\"sign_mnist_train.csv\")\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "685b7561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>...</td>\n",
       "      <td>138</td>\n",
       "      <td>148</td>\n",
       "      <td>127</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "      <td>106</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>126</td>\n",
       "      <td>128</td>\n",
       "      <td>131</td>\n",
       "      <td>132</td>\n",
       "      <td>133</td>\n",
       "      <td>134</td>\n",
       "      <td>135</td>\n",
       "      <td>135</td>\n",
       "      <td>136</td>\n",
       "      <td>...</td>\n",
       "      <td>47</td>\n",
       "      <td>104</td>\n",
       "      <td>194</td>\n",
       "      <td>183</td>\n",
       "      <td>186</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>184</td>\n",
       "      <td>182</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>85</td>\n",
       "      <td>88</td>\n",
       "      <td>92</td>\n",
       "      <td>96</td>\n",
       "      <td>105</td>\n",
       "      <td>123</td>\n",
       "      <td>135</td>\n",
       "      <td>143</td>\n",
       "      <td>147</td>\n",
       "      <td>...</td>\n",
       "      <td>68</td>\n",
       "      <td>166</td>\n",
       "      <td>242</td>\n",
       "      <td>227</td>\n",
       "      <td>230</td>\n",
       "      <td>227</td>\n",
       "      <td>226</td>\n",
       "      <td>225</td>\n",
       "      <td>224</td>\n",
       "      <td>222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>203</td>\n",
       "      <td>205</td>\n",
       "      <td>207</td>\n",
       "      <td>206</td>\n",
       "      <td>207</td>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>210</td>\n",
       "      <td>...</td>\n",
       "      <td>154</td>\n",
       "      <td>248</td>\n",
       "      <td>247</td>\n",
       "      <td>248</td>\n",
       "      <td>253</td>\n",
       "      <td>236</td>\n",
       "      <td>230</td>\n",
       "      <td>240</td>\n",
       "      <td>253</td>\n",
       "      <td>255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>188</td>\n",
       "      <td>191</td>\n",
       "      <td>193</td>\n",
       "      <td>195</td>\n",
       "      <td>199</td>\n",
       "      <td>201</td>\n",
       "      <td>202</td>\n",
       "      <td>203</td>\n",
       "      <td>203</td>\n",
       "      <td>...</td>\n",
       "      <td>26</td>\n",
       "      <td>40</td>\n",
       "      <td>64</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>46</td>\n",
       "      <td>46</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7167</th>\n",
       "      <td>1</td>\n",
       "      <td>135</td>\n",
       "      <td>119</td>\n",
       "      <td>108</td>\n",
       "      <td>102</td>\n",
       "      <td>105</td>\n",
       "      <td>99</td>\n",
       "      <td>61</td>\n",
       "      <td>103</td>\n",
       "      <td>121</td>\n",
       "      <td>...</td>\n",
       "      <td>108</td>\n",
       "      <td>112</td>\n",
       "      <td>116</td>\n",
       "      <td>114</td>\n",
       "      <td>118</td>\n",
       "      <td>180</td>\n",
       "      <td>184</td>\n",
       "      <td>176</td>\n",
       "      <td>167</td>\n",
       "      <td>163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7168</th>\n",
       "      <td>12</td>\n",
       "      <td>157</td>\n",
       "      <td>159</td>\n",
       "      <td>161</td>\n",
       "      <td>164</td>\n",
       "      <td>166</td>\n",
       "      <td>166</td>\n",
       "      <td>171</td>\n",
       "      <td>174</td>\n",
       "      <td>175</td>\n",
       "      <td>...</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>213</td>\n",
       "      <td>211</td>\n",
       "      <td>210</td>\n",
       "      <td>210</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7169</th>\n",
       "      <td>2</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>190</td>\n",
       "      <td>191</td>\n",
       "      <td>190</td>\n",
       "      <td>190</td>\n",
       "      <td>192</td>\n",
       "      <td>192</td>\n",
       "      <td>191</td>\n",
       "      <td>...</td>\n",
       "      <td>216</td>\n",
       "      <td>215</td>\n",
       "      <td>213</td>\n",
       "      <td>214</td>\n",
       "      <td>214</td>\n",
       "      <td>213</td>\n",
       "      <td>210</td>\n",
       "      <td>211</td>\n",
       "      <td>209</td>\n",
       "      <td>208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7170</th>\n",
       "      <td>4</td>\n",
       "      <td>201</td>\n",
       "      <td>205</td>\n",
       "      <td>208</td>\n",
       "      <td>209</td>\n",
       "      <td>214</td>\n",
       "      <td>216</td>\n",
       "      <td>218</td>\n",
       "      <td>223</td>\n",
       "      <td>226</td>\n",
       "      <td>...</td>\n",
       "      <td>112</td>\n",
       "      <td>169</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>237</td>\n",
       "      <td>113</td>\n",
       "      <td>91</td>\n",
       "      <td>67</td>\n",
       "      <td>70</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7171</th>\n",
       "      <td>2</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>174</td>\n",
       "      <td>173</td>\n",
       "      <td>173</td>\n",
       "      <td>175</td>\n",
       "      <td>175</td>\n",
       "      <td>174</td>\n",
       "      <td>...</td>\n",
       "      <td>201</td>\n",
       "      <td>200</td>\n",
       "      <td>197</td>\n",
       "      <td>198</td>\n",
       "      <td>198</td>\n",
       "      <td>197</td>\n",
       "      <td>195</td>\n",
       "      <td>195</td>\n",
       "      <td>193</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7172 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  \\\n",
       "0         6     149     149     150     150     150     151     151     150   \n",
       "1         5     126     128     131     132     133     134     135     135   \n",
       "2        10      85      88      92      96     105     123     135     143   \n",
       "3         0     203     205     207     206     207     209     210     209   \n",
       "4         3     188     191     193     195     199     201     202     203   \n",
       "...     ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "7167      1     135     119     108     102     105      99      61     103   \n",
       "7168     12     157     159     161     164     166     166     171     174   \n",
       "7169      2     190     191     190     191     190     190     192     192   \n",
       "7170      4     201     205     208     209     214     216     218     223   \n",
       "7171      2     173     174     173     174     173     173     175     175   \n",
       "\n",
       "      pixel9  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0        151  ...       138       148       127        89        82        96   \n",
       "1        136  ...        47       104       194       183       186       184   \n",
       "2        147  ...        68       166       242       227       230       227   \n",
       "3        210  ...       154       248       247       248       253       236   \n",
       "4        203  ...        26        40        64        48        29        46   \n",
       "...      ...  ...       ...       ...       ...       ...       ...       ...   \n",
       "7167     121  ...       108       112       116       114       118       180   \n",
       "7168     175  ...       213       213       213       214       213       211   \n",
       "7169     191  ...       216       215       213       214       214       213   \n",
       "7170     226  ...       112       169       255       255       237       113   \n",
       "7171     174  ...       201       200       197       198       198       197   \n",
       "\n",
       "      pixel781  pixel782  pixel783  pixel784  \n",
       "0          106       112       120       107  \n",
       "1          184       184       182       180  \n",
       "2          226       225       224       222  \n",
       "3          230       240       253       255  \n",
       "4           49        46        46        53  \n",
       "...        ...       ...       ...       ...  \n",
       "7167       184       176       167       163  \n",
       "7168       210       210       209       208  \n",
       "7169       210       211       209       208  \n",
       "7170        91        67        70        63  \n",
       "7171       195       195       193       192  \n",
       "\n",
       "[7172 rows x 785 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=pd.read_csv(\"sign_mnist_test.csv\")\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1134eca0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "           ..\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "pixel784    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba1c677",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label       0\n",
       "pixel1      0\n",
       "pixel2      0\n",
       "pixel3      0\n",
       "pixel4      0\n",
       "           ..\n",
       "pixel780    0\n",
       "pixel781    0\n",
       "pixel782    0\n",
       "pixel783    0\n",
       "pixel784    0\n",
       "Length: 785, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "118a8500",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27455, 785)\n",
      "(7172, 785)\n"
     ]
    }
   ],
   "source": [
    "print(train.shape)\n",
    "print(test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3c989d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27455 entries, 0 to 27454\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 164.4 MB\n"
     ]
    }
   ],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58f7d92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 7172 entries, 0 to 7171\n",
      "Columns: 785 entries, label to pixel784\n",
      "dtypes: int64(785)\n",
      "memory usage: 43.0 MB\n"
     ]
    }
   ],
   "source": [
    "test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d6c8c0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.label.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "61f92303",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SLDataset(Dataset):\n",
    "    def __init__(self, file_path):\n",
    "        data = np.loadtxt(file_path, delimiter=',', skiprows=1)\n",
    "        self.x = torch.tensor(data[:, 1:], dtype=torch.float32) / 255.0 \n",
    "        self.y = torch.tensor(data[:, 0], dtype=torch.int64)\n",
    "        self.n_samples = data.shape[0]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0f15c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File paths\n",
    "train_file = 'sign_mnist_train.csv'\n",
    "test_file = 'sign_mnist_test.csv'\n",
    "\n",
    "# Check if files exist\n",
    "if not os.path.exists(train_file) or not os.path.exists(test_file):\n",
    "    raise FileNotFoundError(\"Dataset files not found. Please ensure 'sign_mnist_train.csv' and 'sign_mnist_test.csv' are in the working directory.\")\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = SLDataset(train_file)\n",
    "test_dataset = SLDataset(test_file)\n",
    "\n",
    "# DataLoaders\n",
    "batch_size = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a47e72e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear3 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear3(out) \n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef22de02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94631b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "input_size = 784  # 28x28 images\n",
    "hidden_size = 784\n",
    "num_classes = 25\n",
    "learning_rate = 0.001\n",
    "num_epochs = 32   \n",
    "\n",
    "# Initialize model, loss, and optimizer\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device) # Move model to device\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c7f16f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the model's parameters are in Float32\n",
    "model = model.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3dc6a640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/32], Step [100/429], Loss: 2.2666\n",
      "Epoch [1/32], Step [200/429], Loss: 1.7242\n",
      "Epoch [1/32], Step [300/429], Loss: 1.6605\n",
      "Epoch [1/32], Step [400/429], Loss: 1.2948\n",
      "Epoch [2/32], Step [100/429], Loss: 1.3751\n",
      "Epoch [2/32], Step [200/429], Loss: 0.6110\n",
      "Epoch [2/32], Step [300/429], Loss: 0.7280\n",
      "Epoch [2/32], Step [400/429], Loss: 0.8781\n",
      "Epoch [3/32], Step [100/429], Loss: 0.7798\n",
      "Epoch [3/32], Step [200/429], Loss: 0.5022\n",
      "Epoch [3/32], Step [300/429], Loss: 0.4650\n",
      "Epoch [3/32], Step [400/429], Loss: 0.5164\n",
      "Epoch [4/32], Step [100/429], Loss: 0.3007\n",
      "Epoch [4/32], Step [200/429], Loss: 0.2821\n",
      "Epoch [4/32], Step [300/429], Loss: 0.3560\n",
      "Epoch [4/32], Step [400/429], Loss: 0.2049\n",
      "Epoch [5/32], Step [100/429], Loss: 0.2862\n",
      "Epoch [5/32], Step [200/429], Loss: 0.1190\n",
      "Epoch [5/32], Step [300/429], Loss: 0.1574\n",
      "Epoch [5/32], Step [400/429], Loss: 0.1145\n",
      "Epoch [6/32], Step [100/429], Loss: 0.0971\n",
      "Epoch [6/32], Step [200/429], Loss: 0.2017\n",
      "Epoch [6/32], Step [300/429], Loss: 0.0575\n",
      "Epoch [6/32], Step [400/429], Loss: 0.0754\n",
      "Epoch [7/32], Step [100/429], Loss: 0.0749\n",
      "Epoch [7/32], Step [200/429], Loss: 0.0405\n",
      "Epoch [7/32], Step [300/429], Loss: 0.0685\n",
      "Epoch [7/32], Step [400/429], Loss: 0.0379\n",
      "Epoch [8/32], Step [100/429], Loss: 0.2094\n",
      "Epoch [8/32], Step [200/429], Loss: 0.1332\n",
      "Epoch [8/32], Step [300/429], Loss: 0.3401\n",
      "Epoch [8/32], Step [400/429], Loss: 0.0223\n",
      "Epoch [9/32], Step [100/429], Loss: 0.0053\n",
      "Epoch [9/32], Step [200/429], Loss: 0.0048\n",
      "Epoch [9/32], Step [300/429], Loss: 0.0197\n",
      "Epoch [9/32], Step [400/429], Loss: 0.0173\n",
      "Epoch [10/32], Step [100/429], Loss: 0.0078\n",
      "Epoch [10/32], Step [200/429], Loss: 0.0019\n",
      "Epoch [10/32], Step [300/429], Loss: 0.0028\n",
      "Epoch [10/32], Step [400/429], Loss: 0.0038\n",
      "Epoch [11/32], Step [100/429], Loss: 0.1816\n",
      "Epoch [11/32], Step [200/429], Loss: 0.0638\n",
      "Epoch [11/32], Step [300/429], Loss: 0.0229\n",
      "Epoch [11/32], Step [400/429], Loss: 0.0030\n",
      "Epoch [12/32], Step [100/429], Loss: 0.0031\n",
      "Epoch [12/32], Step [200/429], Loss: 0.0052\n",
      "Epoch [12/32], Step [300/429], Loss: 0.0019\n",
      "Epoch [12/32], Step [400/429], Loss: 0.0025\n",
      "Epoch [13/32], Step [100/429], Loss: 0.0013\n",
      "Epoch [13/32], Step [200/429], Loss: 0.0018\n",
      "Epoch [13/32], Step [300/429], Loss: 0.0006\n",
      "Epoch [13/32], Step [400/429], Loss: 0.0030\n",
      "Epoch [14/32], Step [100/429], Loss: 0.0015\n",
      "Epoch [14/32], Step [200/429], Loss: 0.0008\n",
      "Epoch [14/32], Step [300/429], Loss: 0.0037\n",
      "Epoch [14/32], Step [400/429], Loss: 0.0015\n",
      "Epoch [15/32], Step [100/429], Loss: 2.2636\n",
      "Epoch [15/32], Step [200/429], Loss: 0.1329\n",
      "Epoch [15/32], Step [300/429], Loss: 0.0381\n",
      "Epoch [15/32], Step [400/429], Loss: 0.0245\n",
      "Epoch [16/32], Step [100/429], Loss: 0.0074\n",
      "Epoch [16/32], Step [200/429], Loss: 0.0061\n",
      "Epoch [16/32], Step [300/429], Loss: 0.0037\n",
      "Epoch [16/32], Step [400/429], Loss: 0.0063\n",
      "Epoch [17/32], Step [100/429], Loss: 0.0039\n",
      "Epoch [17/32], Step [200/429], Loss: 0.0023\n",
      "Epoch [17/32], Step [300/429], Loss: 0.0023\n",
      "Epoch [17/32], Step [400/429], Loss: 0.7217\n",
      "Epoch [18/32], Step [100/429], Loss: 0.0139\n",
      "Epoch [18/32], Step [200/429], Loss: 0.0036\n",
      "Epoch [18/32], Step [300/429], Loss: 0.0049\n",
      "Epoch [18/32], Step [400/429], Loss: 0.0017\n",
      "Epoch [19/32], Step [100/429], Loss: 0.0017\n",
      "Epoch [19/32], Step [200/429], Loss: 0.0011\n",
      "Epoch [19/32], Step [300/429], Loss: 0.0014\n",
      "Epoch [19/32], Step [400/429], Loss: 0.0017\n",
      "Epoch [20/32], Step [100/429], Loss: 0.0012\n",
      "Epoch [20/32], Step [200/429], Loss: 0.0020\n",
      "Epoch [20/32], Step [300/429], Loss: 0.0013\n",
      "Epoch [20/32], Step [400/429], Loss: 0.0009\n",
      "Epoch [21/32], Step [100/429], Loss: 0.0006\n",
      "Epoch [21/32], Step [200/429], Loss: 0.0014\n",
      "Epoch [21/32], Step [300/429], Loss: 0.0013\n",
      "Epoch [21/32], Step [400/429], Loss: 0.0014\n",
      "Epoch [22/32], Step [100/429], Loss: 0.0006\n",
      "Epoch [22/32], Step [200/429], Loss: 0.1188\n",
      "Epoch [22/32], Step [300/429], Loss: 0.0093\n",
      "Epoch [22/32], Step [400/429], Loss: 0.0068\n",
      "Epoch [23/32], Step [100/429], Loss: 0.0061\n",
      "Epoch [23/32], Step [200/429], Loss: 0.0030\n",
      "Epoch [23/32], Step [300/429], Loss: 0.0035\n",
      "Epoch [23/32], Step [400/429], Loss: 0.0028\n",
      "Epoch [24/32], Step [100/429], Loss: 0.0037\n",
      "Epoch [24/32], Step [200/429], Loss: 0.0025\n",
      "Epoch [24/32], Step [300/429], Loss: 0.0016\n",
      "Epoch [24/32], Step [400/429], Loss: 0.0018\n",
      "Epoch [25/32], Step [100/429], Loss: 0.0018\n",
      "Epoch [25/32], Step [200/429], Loss: 0.0022\n",
      "Epoch [25/32], Step [300/429], Loss: 0.0012\n",
      "Epoch [25/32], Step [400/429], Loss: 0.0012\n",
      "Epoch [26/32], Step [100/429], Loss: 0.0008\n",
      "Epoch [26/32], Step [200/429], Loss: 0.0023\n",
      "Epoch [26/32], Step [300/429], Loss: 0.0006\n",
      "Epoch [26/32], Step [400/429], Loss: 0.0015\n",
      "Epoch [27/32], Step [100/429], Loss: 0.0005\n",
      "Epoch [27/32], Step [200/429], Loss: 0.0010\n",
      "Epoch [27/32], Step [300/429], Loss: 0.3834\n",
      "Epoch [27/32], Step [400/429], Loss: 0.0149\n",
      "Epoch [28/32], Step [100/429], Loss: 0.0138\n",
      "Epoch [28/32], Step [200/429], Loss: 0.0088\n",
      "Epoch [28/32], Step [300/429], Loss: 0.0075\n",
      "Epoch [28/32], Step [400/429], Loss: 0.0082\n",
      "Epoch [29/32], Step [100/429], Loss: 0.0029\n",
      "Epoch [29/32], Step [200/429], Loss: 0.0051\n",
      "Epoch [29/32], Step [300/429], Loss: 0.0116\n",
      "Epoch [29/32], Step [400/429], Loss: 0.2649\n",
      "Epoch [30/32], Step [100/429], Loss: 0.0035\n",
      "Epoch [30/32], Step [200/429], Loss: 0.0029\n",
      "Epoch [30/32], Step [300/429], Loss: 0.0053\n",
      "Epoch [30/32], Step [400/429], Loss: 0.0019\n",
      "Epoch [31/32], Step [100/429], Loss: 0.0020\n",
      "Epoch [31/32], Step [200/429], Loss: 0.0011\n",
      "Epoch [31/32], Step [300/429], Loss: 0.0012\n",
      "Epoch [31/32], Step [400/429], Loss: 0.0014\n",
      "Epoch [32/32], Step [100/429], Loss: 0.0011\n",
      "Epoch [32/32], Step [200/429], Loss: 0.0011\n",
      "Epoch [32/32], Step [300/429], Loss: 0.0007\n",
      "Epoch [32/32], Step [400/429], Loss: 0.0009\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "total_steps_train = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Ensure images are in the correct dtype\n",
    "        images = images.to(torch.float32)\n",
    "        labels = labels.to(torch.int64)\n",
    "\n",
    "        # Flatten images to match the input size of the model\n",
    "        images = images.view(-1, 28 * 28)  # Flatten into [batch_size, 784]\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Step [{i + 1}/{total_steps_train}], Loss: {loss.item():.4f}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "94ed030a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 82.19464584495259 %\n",
      "F1 score: 0.8192339857550789\n"
     ]
    }
   ],
   "source": [
    "total_steps_test = len(test_loader)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    pred=[]\n",
    "    for image, label in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(torch.int64)\n",
    "        outputs = model(image)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        n_samples += label.size(0)\n",
    "        n_correct += (predicted == label).sum().item()\n",
    "        pred.append(predicted.data)\n",
    "        \n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')\n",
    "    \n",
    "# Label value of the test dataset\n",
    "act_list=test[\"label\"].tolist()\n",
    "    \n",
    "# To fetch the value of the pred list\n",
    "pred_list=[]\n",
    "for i in range(total_steps_test):\n",
    "    for j in pred[i]:\n",
    "        pred_list.append(j.item())\n",
    "        \n",
    "# To find F1 score\n",
    "f1=f1_score(act_list, pred_list, average=\"weighted\")\n",
    "print(f\"F1 score: {f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afa57cf",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0aa7903a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label=test.iloc[:1, :1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e16b3815",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_label=[]\n",
    "for i in range(1):\n",
    "    sample_label.append(test_label.values[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4334c9ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[6]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "092b8c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sample = test.iloc[:1, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "431b6260",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>pixel9</th>\n",
       "      <th>pixel10</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "      <th>pixel784</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>149</td>\n",
       "      <td>149</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>151</td>\n",
       "      <td>150</td>\n",
       "      <td>151</td>\n",
       "      <td>152</td>\n",
       "      <td>...</td>\n",
       "      <td>138</td>\n",
       "      <td>148</td>\n",
       "      <td>127</td>\n",
       "      <td>89</td>\n",
       "      <td>82</td>\n",
       "      <td>96</td>\n",
       "      <td>106</td>\n",
       "      <td>112</td>\n",
       "      <td>120</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 784 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  pixel8  pixel9  \\\n",
       "0     149     149     150     150     150     151     151     150     151   \n",
       "\n",
       "   pixel10  ...  pixel775  pixel776  pixel777  pixel778  pixel779  pixel780  \\\n",
       "0      152  ...       138       148       127        89        82        96   \n",
       "\n",
       "   pixel781  pixel782  pixel783  pixel784  \n",
       "0       106       112       120       107  \n",
       "\n",
       "[1 rows x 784 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c0325fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample= torch.from_numpy(test_sample.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8225795",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample=sample.to(torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4175d24f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[149., 149., 150., 150., 150., 151., 151., 150., 151., 152., 152., 152.,\n",
       "         152., 152., 153., 153., 151., 152., 152., 153., 152., 152., 151., 151.,\n",
       "         150., 150., 150., 149., 150., 150., 150., 152., 152., 151., 152., 152.,\n",
       "         152., 152., 152., 153., 154., 153., 154., 154., 153., 154., 153., 154.,\n",
       "         153., 153., 152., 152., 152., 151., 150., 151., 150., 151., 151., 152.,\n",
       "         152., 152., 153., 153., 152., 152., 152., 153., 154., 154., 155., 155.,\n",
       "         154., 154., 155., 155., 155., 155., 154., 153., 153., 151., 151., 152.,\n",
       "         150., 151., 151., 152., 152., 152., 154., 154., 154., 154., 154., 153.,\n",
       "         154., 155., 156., 157., 157., 156., 155., 156., 155., 154., 154., 155.,\n",
       "         152., 154., 153., 153., 151., 152., 152., 152., 154., 154., 154., 154.,\n",
       "         154., 155., 157., 156., 156., 156., 154., 150., 146., 147., 146., 147.,\n",
       "         143., 137., 126., 126., 142., 139., 152., 154., 152., 153., 153., 154.,\n",
       "         154., 155., 154., 155., 155., 154., 153., 150., 144., 143., 145., 139.,\n",
       "         142., 144., 157., 157., 147., 139., 128., 119., 130., 113., 147., 156.,\n",
       "         151., 153., 153., 155., 155., 156., 155., 152., 145., 139., 141., 141.,\n",
       "         141., 153., 153., 143., 135., 137., 139., 133., 121., 107., 101., 104.,\n",
       "         110., 127., 157., 156., 151., 152., 153., 155., 155., 154., 151., 146.,\n",
       "         139., 131., 130., 134., 137., 132., 125., 111., 101.,  94.,  95., 105.,\n",
       "         113., 122., 133., 145., 153., 157., 156., 156., 152., 152., 154., 152.,\n",
       "         151., 150., 149., 149., 139., 122., 104.,  98.,  92.,  82.,  81.,  81.,\n",
       "          85., 114., 145., 157., 160., 162., 161., 159., 157., 156., 156., 156.,\n",
       "         151., 151., 150., 146., 145., 147., 148., 147., 145., 132.,  97.,  71.,\n",
       "          62.,  66.,  88., 116., 145., 162., 160., 159., 157., 155., 156., 157.,\n",
       "         157., 156., 155., 155., 151., 145., 144., 145., 147., 145., 147., 150.,\n",
       "         150., 124.,  92.,  68.,  63.,  67.,  86., 159., 163., 155., 158., 157.,\n",
       "         156., 156., 157., 156., 156., 156., 155., 154., 143., 144., 145., 145.,\n",
       "         143., 147., 152., 152., 128.,  90.,  79.,  68.,  64.,  70.,  67.,  84.,\n",
       "         147., 164., 157., 158., 157., 157., 157., 156., 157., 156., 156., 155.,\n",
       "         145., 146., 143., 145., 145., 150., 149., 149., 139., 118.,  85.,  62.,\n",
       "          62.,  75.,  73.,  62.,  67., 140., 164., 157., 158., 158., 158., 158.,\n",
       "         157., 157., 156., 156., 150., 147., 144., 147., 149., 148., 149., 158.,\n",
       "         158., 136.,  94.,  63.,  58.,  69.,  85.,  82.,  67.,  70., 156., 160.,\n",
       "         159., 160., 159., 158., 157., 156., 156., 156., 147., 148., 147., 145.,\n",
       "         148., 152., 151., 160., 153., 119.,  86.,  66.,  64.,  63.,  69.,  75.,\n",
       "          78.,  57., 130., 165., 158., 159., 158., 159., 158., 157., 157., 157.,\n",
       "         149., 148., 146., 145., 147., 149., 146., 151., 144., 110.,  78.,  65.,\n",
       "          66.,  66.,  58.,  59.,  64.,  79., 150., 165., 162., 162., 162., 162.,\n",
       "         161., 161., 158., 156., 151., 146., 143., 141., 138., 140., 142., 146.,\n",
       "         144., 121.,  84.,  56.,  62.,  70.,  71.,  68.,  57., 117., 144., 144.,\n",
       "         147., 149., 152., 150., 146., 146., 154., 160., 147., 144., 143., 142.,\n",
       "         140., 142., 146., 151., 154., 131.,  85.,  59.,  51.,  60.,  85.,  69.,\n",
       "          64.,  76.,  75.,  79.,  81.,  79.,  76.,  83., 112., 141., 163., 163.,\n",
       "         144., 148., 147., 145., 145., 148., 150., 155., 151., 119.,  74.,  62.,\n",
       "          63.,  55.,  62.,  72.,  73.,  77.,  74.,  73.,  68.,  88., 113., 138.,\n",
       "         162., 162., 168., 168., 146., 146., 142., 141., 141., 138., 134., 142.,\n",
       "         124.,  96.,  75.,  67.,  65.,  63.,  62.,  78.,  87.,  76.,  84.,  96.,\n",
       "         126., 162., 172., 155., 144., 149., 151., 161., 142., 136., 132., 134.,\n",
       "         127., 119., 118., 119., 103.,  87.,  77.,  73.,  70.,  62.,  64.,  72.,\n",
       "          93., 134., 155., 160., 166., 156., 150., 151., 143., 136., 145., 149.,\n",
       "         130., 132., 127., 120., 114., 110., 109., 105.,  91.,  77.,  74.,  75.,\n",
       "          74.,  65.,  73., 113., 166., 177., 170., 161., 152., 141., 134., 136.,\n",
       "         140., 133., 127., 130., 113., 116., 115., 106., 101.,  95.,  86.,  84.,\n",
       "          85.,  77.,  78.,  74.,  76., 103., 152., 179., 170., 157., 155., 151.,\n",
       "         140., 129., 126., 126., 133., 130., 122., 125.,  81.,  86.,  85.,  83.,\n",
       "          76.,  72.,  73.,  76.,  77.,  79.,  71., 101., 151., 178., 177., 170.,\n",
       "         161., 152., 147., 151., 133., 115., 121., 121., 124., 126., 122., 122.,\n",
       "          61.,  61.,  67.,  69.,  70.,  75.,  78.,  78.,  81.,  68., 113., 165.,\n",
       "         174., 169., 162., 157., 149., 148., 148., 148., 126., 100., 113., 117.,\n",
       "         113., 122., 118., 115.,  69.,  69.,  77.,  78.,  75.,  76.,  78.,  79.,\n",
       "          67., 120., 173., 157., 159., 148., 155., 150., 138., 143., 148., 149.,\n",
       "         123.,  91., 101., 111., 111., 116., 113., 118.,  74.,  75.,  76.,  75.,\n",
       "          75.,  76.,  75.,  68., 124., 172., 152., 146., 146., 146., 152., 142.,\n",
       "         131., 134., 144., 147., 125.,  87.,  87., 103., 107., 110., 116., 113.,\n",
       "          75.,  74.,  74.,  74.,  76.,  74.,  82., 134., 168., 155., 146., 137.,\n",
       "         145., 146., 149., 135., 124., 125., 138., 148., 127.,  89.,  82.,  96.,\n",
       "         106., 112., 120., 107.]], dtype=torch.float32)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9bddb79",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction=model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea616d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-11778.8633,  -7572.8945,   -856.1343, -10566.1562, -10058.0146,\n",
       "          -1954.8785,   3163.5095,  -1519.3680,  -7525.7617,  -7894.4585,\n",
       "          -8107.8950,  -6044.5171,  -4832.2544,  -4747.5049,  -1551.4354,\n",
       "          -4072.6484,  -1733.0375,  -8529.1885,  -7693.5737,   -462.5956,\n",
       "          -6784.9175,  -3314.4241,  -6343.2163,   -782.5171,  -8431.0771]],\n",
       "       dtype=torch.float32, grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b502c0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    " _, predicted = torch.max(prediction.data, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "333e5f8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f09ab8d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i in range(1):\n",
    "    plt.subplot(1, 1, i+1)\n",
    "    plt.imshow(sample[i].reshape(28, 28))\n",
    "    plt.xlabel(f\"(Predicted value: {predicted[i]}, Actual value: {sample_label[i]})\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bf9fb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
